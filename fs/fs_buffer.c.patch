--- original/fs/buffer.c	2020-05-07 08:06:19.944206250 +0200
+++ changed/fs/buffer.c	2019-06-03 13:39:53.000000000 +0200
@@ -617,6 +617,13 @@ void mark_buffer_dirty_inode(struct buff
 }
 EXPORT_SYMBOL(mark_buffer_dirty_inode);
 
+void mark_buffer_dirty_inode_sync(struct buffer_head *bh, struct inode *inode)
+{
+	set_buffer_sync_flush(bh);
+	mark_buffer_dirty_inode(bh, inode);
+}
+EXPORT_SYMBOL(mark_buffer_dirty_inode_sync);
+
 #ifdef CONFIG_BLK_DEV_IO_TRACE
 static inline void save_dirty_task(struct page *page)
 {
@@ -1180,6 +1187,34 @@ void mark_buffer_dirty(struct buffer_hea
 }
 EXPORT_SYMBOL(mark_buffer_dirty);
 
+void mark_buffer_dirty_sync(struct buffer_head *bh)
+{
+	WARN_ON_ONCE(!buffer_uptodate(bh));
+
+	/*
+	 * Very *carefully* optimize the it-is-already-dirty case.
+	 *
+	 * Don't let the final "is it dirty" escape to before we
+	 * perhaps modified the buffer.
+	 */
+	if (buffer_dirty(bh)) {
+		smp_mb();
+		if (buffer_dirty(bh))
+			return;
+	}
+
+	set_buffer_sync_flush(bh);
+	if (!test_set_buffer_dirty(bh)) {
+		struct page *page = bh->b_page;
+		if (!TestSetPageDirty(page)) {
+			struct address_space *mapping = page_mapping(page);
+			if (mapping)
+				__set_page_dirty(page, mapping, 0);
+		}
+	}
+}
+EXPORT_SYMBOL(mark_buffer_dirty_sync);
+
 /*
  * Decrement a buffer_head's reference count.  If all buffers against a page
  * have zero reference count, are clean and unlocked, and if the page is clean
@@ -3090,6 +3125,22 @@ int _submit_bh(int rw, struct buffer_hea
 	if (buffer_prio(bh))
 		rw |= REQ_PRIO;
 
+	if(buffer_sync_flush(bh)) {
+		rw |= REQ_SYNC;
+		clear_buffer_sync_flush(bh);
+	}
+
+#ifdef CONFIG_JOURNAL_DATA_TAG
+	if(buffer_journal(bh)) {
+		set_bit(BIO_JOURNAL, &bio->bi_flags);
+		clear_buffer_journal(bh);
+	}
+	if(buffer_jmeta(bh)) {
+		//set_bit(BIO_JMETA, &bio->bi_flags);
+		clear_buffer_jmeta(bh);
+	}
+#endif
+
 	bio_get(bio);
 	submit_bio(rw, bio);
 
