--- original/drivers/thermal/msm_thermal.c	2020-05-07 08:31:25.710787923 +0200
+++ changed/drivers/thermal/msm_thermal.c	2019-06-03 13:39:52.000000000 +0200
@@ -49,6 +49,13 @@
 #include <linux/suspend.h>
 #include <linux/uaccess.h>
 #include <linux/uio_driver.h>
+#include <linux/sec_debug.h>
+#ifdef CONFIG_SEC_AP_HEALTH
+#include <linux/sec_param.h>
+#endif
+#ifdef CONFIG_SEC_PM
+#include <linux/delay.h>
+#endif
 #include <linux/msm-bus.h>
 
 #define CREATE_TRACE_POINTS
@@ -77,7 +84,7 @@
 #define UIO_VERSION "1.0"
 #define THERM_DDR_MASTER_ID  1
 #define THERM_DDR_SLAVE_ID   512
-#define THERM_DDR_IB_VOTE_REQ   366000000
+#define THERM_DDR_IB_VOTE_REQ   6400000000
 
 #define VALIDATE_AND_SET_MASK(_node, _key, _mask, _cpu) \
 	do { \
@@ -250,6 +257,12 @@ struct cpu_info {
 	uint32_t limited_min_freq;
 	bool freq_thresh_clear;
 	struct cluster_info *parent_ptr;
+#ifdef CONFIG_SEC_AP_HEALTH
+	uint32_t acc_throttled_count;
+	uint32_t acc_hotplug_count;
+	bool mitigation_by_engine;
+	bool mitigation_by_ktm;
+#endif
 };
 
 struct rail {
@@ -492,6 +505,81 @@ static ssize_t thermal_config_debugfs_wr
 		}                                                             \
 	} while (0)
 
+#ifdef CONFIG_SEC_AP_HEALTH
+static ap_health_t *ap_health;
+
+static void update_cpu_throttled_count(cpumask_t *mask)
+{
+	int cpu;
+
+	if (!mask)
+		return;
+
+	if (ap_health == NULL)
+		ap_health = ap_health_data_read();
+
+	for_each_cpu(cpu, mask) {
+		if (cpus[cpu].mitigation_by_engine || cpus[cpu].mitigation_by_ktm) {
+			cpus[cpu].acc_throttled_count++;
+			if (ap_health == NULL)
+				pr_err("%s: throttle cpu%d, %u times - not stored\n",
+					__func__, cpu, cpus[cpu].acc_throttled_count);
+			else {
+				ap_health->thermal.cpu_throttle_cnt[cpu]++;
+				ap_health->daily_thermal.cpu_throttle_cnt[cpu]++;
+				ap_health_data_write(ap_health);
+				pr_err("%s: throttle cpu%d, %u, %u, %u times\n",
+					__func__, cpu, cpus[cpu].acc_throttled_count,
+					ap_health->thermal.cpu_throttle_cnt[cpu],
+					ap_health->daily_thermal.cpu_throttle_cnt[cpu]);
+			}
+		}
+	}
+
+	return;
+}
+
+static void update_hotplug_count(int cpu)
+{
+	cpus[cpu].acc_hotplug_count++;
+
+	if (ap_health == NULL)
+		ap_health = ap_health_data_read();
+
+	if (ap_health == NULL)
+		pr_err("%s: hotplug cpu%d, %u times - not stored\n",
+			__func__, cpu, cpus[cpu].acc_hotplug_count);
+	else {
+		ap_health->thermal.cpu_hotplug_cnt[cpu]++;
+		ap_health->daily_thermal.cpu_hotplug_cnt[cpu]++;
+		ap_health_data_write(ap_health);
+		pr_err("%s: hotplug cpu%d, %u, %u, %u times\n",
+			__func__, cpu, cpus[cpu].acc_hotplug_count,
+			ap_health->thermal.cpu_hotplug_cnt[cpu],
+			ap_health->daily_thermal.cpu_hotplug_cnt[cpu]);
+	}
+
+	return;
+}
+
+static void update_thermal_reset_count(void)
+{
+	if (ap_health == NULL)
+		ap_health = ap_health_data_read();
+
+	if (ap_health != NULL) {
+		ap_health->thermal.ktm_reset_cnt++;
+		ap_health->daily_thermal.ktm_reset_cnt++;
+		ap_health_data_write(ap_health);
+		pr_err("%s: %u %u times\n",
+			__func__, ap_health->thermal.ktm_reset_cnt,
+			ap_health->daily_thermal.ktm_reset_cnt);
+	}
+
+	return;
+}
+#endif /* CONFIG_SEC_AP_HEALTH */
+
 static void uio_init(struct platform_device *pdev)
 {
 	int ret = 0;
@@ -1016,6 +1104,9 @@ static void update_cpu_freq(int cpu)
 		} else if (!cpumask_intersects(&mask, &throttling_mask)) {
 			cpumask_or(&throttling_mask, &mask, &throttling_mask);
 			set_cpu_throttled(&mask, true);
+#ifdef CONFIG_SEC_AP_HEALTH
+			update_cpu_throttled_count(&mask);
+#endif
 		}
 		trace_thermal_pre_frequency_mit(cpu,
 			cpus[cpu].limited_max_freq,
@@ -2711,9 +2802,42 @@ static void msm_thermal_bite(int zone_id
 	struct scm_desc desc;
 	int tsens_id = 0;
 	int ret = 0;
+/* Workaround for Tsens temp adc bit error */
+#ifdef CONFIG_SEC_PM
+	int sensor_id, id_type, i;
 
 	ret = zone_id_to_tsen_id(zone_id, &tsens_id);
 	if (ret < 0) {
+		sensor_id = zone_id;
+		id_type = THERM_ZONE_ID;
+	} else {
+		sensor_id = tsens_id;
+		id_type = THERM_TSENS_ID;
+	}
+
+	for(i = 0; i < 2; i++) {
+		msleep(1000); /* waiting 1sec for tsens update */
+		ret = therm_get_temp(sensor_id, id_type, &temp);
+		if (ret) {
+			pr_err("Unable to read sensor:%d. err:%d\n",
+				sensor_id, ret);
+			continue;
+		}
+
+		if(temp < msm_thermal_info.therm_reset_temp_degC) {
+			pr_err("Z:%d, T:%d, retry temperature:%ld, Skip SW System reset\n",
+				zone_id, tsens_id, temp);
+			return;
+		}
+	}
+#endif
+
+#ifdef CONFIG_SEC_AP_HEALTH
+	update_thermal_reset_count();
+#endif
+	sec_debug_set_thermal_upload();
+	ret = zone_id_to_tsen_id(zone_id, &tsens_id);
+	if (ret < 0) {
 		pr_err("Zone:%d reached temperature:%ld. Err = %d System reset\n",
 			zone_id, temp, ret);
 	} else {
@@ -2730,6 +2854,14 @@ static void msm_thermal_bite(int zone_id
 	}
 }
 
+#ifdef CONFIG_USER_RESET_DEBUG_TEST
+void force_thermal_reset(void)
+{
+	msm_thermal_bite(0, msm_thermal_info.therm_reset_temp_degC);
+}
+EXPORT_SYMBOL(force_thermal_reset);
+#endif
+
 static int do_therm_reset(void)
 {
 	int ret = 0, i;
@@ -2898,9 +3030,14 @@ static void __ref do_core_control(long t
 				cpu_dev = get_cpu_device(i);
 				trace_thermal_pre_core_offline(i);
 				ret = device_offline(cpu_dev);
-				if (ret < 0)
+				if (ret < 0) {
 					pr_err("Error %d offline core %d\n",
 					       ret, i);
+#ifdef CONFIG_SEC_AP_HEALTH
+				} else {
+					update_hotplug_count(i);
+#endif
+				}
 				trace_thermal_post_core_offline(i,
 					cpumask_test_cpu(i, cpu_online_mask));
 			}
@@ -2946,6 +3083,7 @@ static void __ref do_core_control(long t
 	}
 	mutex_unlock(&core_control_mutex);
 }
+
 /* Call with core_control_mutex locked */
 static int __ref update_offline_cores(int val)
 {
@@ -2979,6 +3117,9 @@ static int __ref update_offline_cores(in
 				pend_hotplug_req = true;
 			} else {
 				pr_debug("Offlined CPU%d\n", cpu);
+#ifdef CONFIG_SEC_AP_HEALTH
+				update_hotplug_count(cpu);
+#endif
 			}
 			trace_thermal_post_core_offline(cpu,
 				cpumask_test_cpu(cpu, cpu_online_mask));
@@ -3784,6 +3925,9 @@ static int freq_mitigation_notify(enum t
 				cpu_node->cpu, msm_thermal_info.freq_limit);
 
 			cpu_node->max_freq = true;
+#ifdef CONFIG_SEC_AP_HEALTH
+			cpus[cpu_node->cpu].mitigation_by_ktm = true;
+#endif
 		}
 		break;
 	case THERMAL_TRIP_CONFIGURABLE_LOW:
@@ -3793,6 +3937,9 @@ static int freq_mitigation_notify(enum t
 				cpu_node->cpu);
 
 			cpu_node->max_freq = false;
+#ifdef CONFIG_SEC_AP_HEALTH
+			cpus[cpu_node->cpu].mitigation_by_ktm = false;
+#endif
 		}
 		break;
 	default:
@@ -4014,6 +4161,19 @@ int msm_thermal_set_cluster_freq(uint32_
 			pr_err("Cluster%d is not synchronous\n", cluster);
 			return -EINVAL;
 		} else {
+#ifdef CONFIG_SEC_AP_HEALTH
+			if (is_max) {
+				if (freq >= cluster_ptr->freq_table[cluster_ptr->freq_idx_high].frequency) {
+					for_each_cpu_mask(i, cluster_ptr->cluster_cores) {
+						cpus[i].mitigation_by_engine = false;
+					}
+				}
+				else
+					for_each_cpu_mask(i, cluster_ptr->cluster_cores) {
+						cpus[i].mitigation_by_engine = true;
+					}
+			}
+#endif
 			pr_debug("Update Cluster%d %s frequency to %d\n",
 				cluster, (is_max) ? "max" : "min", freq);
 			break;
@@ -7469,8 +7629,31 @@ static struct platform_driver msm_therma
 	.remove = msm_thermal_dev_exit,
 };
 
+#ifdef CONFIG_SEC_AP_HEALTH
+static int msm_thermal_sec_param_notifier_callback(
+	struct notifier_block *nfb, unsigned long action, void *data)
+{
+	switch (action) {
+		case SEC_PARAM_DRV_INIT_DONE:
+			ap_health = ap_health_data_read();
+			break;
+		default:
+			return NOTIFY_DONE;
+	}
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block msm_thermal_sec_param_notifier = {
+	.notifier_call = msm_thermal_sec_param_notifier_callback,
+};
+#endif /* CONFIG_SEC_AP_HEALTH */
+
 int __init msm_thermal_device_init(void)
 {
+#ifdef CONFIG_SEC_AP_HEALTH
+	sec_param_notifier_register(&msm_thermal_sec_param_notifier);
+#endif
 	return platform_driver_register(&msm_thermal_device_driver);
 }
 arch_initcall(msm_thermal_device_init);
